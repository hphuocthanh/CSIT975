{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 - Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a: Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMSE(theta0, theta1, n, X,Y):\n",
    "  Y_pred = theta0 + theta1 * X\n",
    "  return np.sum(np.square(np.subtract(Y_pred, Y))) / (2*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.40000000000000013\n"
     ]
    }
   ],
   "source": [
    "print(calculateMSE(0, 1, 4, np.array([1,2,3,4]), np.array([2,1,4,3])))\n",
    "print(calculateMSE(1, 3/5, 4, np.array([1,2,3,4]), np.array([2,1,4,3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b: Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 1.9250000000000005, theta_0 = 0.5, theta_1 = 1.4000000000000001\n",
      "Iteration 1: Loss = 1.1043750000000003, theta_0 = 0.19999999999999996, theta_1 = 0.44999999999999996\n",
      "Iteration 2: Loss = 0.7347687499999997, theta_0 = 0.43499999999999994, theta_1 = 1.075\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def gradient_descent(X, Y, learning_rate, num_iterations):\n",
    "    theta_0, theta_1 = 0, 0 # theta_1, theta_0\n",
    "    n = len(X)\n",
    "    for i in range(num_iterations):\n",
    "        Y_pred = theta_1 * X + theta_0\n",
    "        D_theta_1 = (-1/n) * sum(X * (Y - Y_pred))\n",
    "        D_theta_0 = (-1/n) * sum(Y - Y_pred)\n",
    "        theta_1 = theta_1 - learning_rate * D_theta_1\n",
    "        theta_0 = theta_0 - learning_rate * D_theta_0\n",
    "        print(f\"Iteration {i}: Loss = {calculateMSE(theta_0, theta_1, n, X, Y)}, theta_0 = {theta_0}, theta_1 = {theta_1}\")\n",
    "    return theta_0, theta_1\n",
    "\n",
    "# Example usage with some data:\n",
    "X = np.array([1,2, 3,4])\n",
    "Y = np.array([2,1,4,3])\n",
    "theta_0_final, theta_1_final = gradient_descent(X, Y, learning_rate=0.2, num_iterations=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "  return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(THETA, X):\n",
    "  return sigmoid(np.dot(np.array(THETA).T, np.array(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7310585786300049\n"
     ]
    }
   ],
   "source": [
    "THETA = [1, 2, -1, 5]\n",
    "X = [1, 0, 10, 2]\n",
    "\n",
    "print(logistic_regression(THETA, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "THETA = [-6, 0.05, 1]\n",
    "X = [1, 50, 3.5]\n",
    "\n",
    "print(logistic_regression(THETA, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['content' 'filtering' 'interested' 'interesting' 'model' 'spam' 'spams'\n",
      " 'studying' 'subfield']\n",
      "[[0.54783215 0.42544054 0.         0.         0.72033345 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.24396579 0.5683836  0.         0.         0.         0.64157139\n",
      "  0.         0.3207857  0.3207857 ]\n",
      " [0.         0.32274454 0.54645401 0.54645401 0.         0.\n",
      "  0.54645401 0.         0.        ]]\n",
      "['content' 'filtering' 'interested' 'interesting' 'model' 'spam' 'spams'\n",
      " 'studying' 'subfield']\n",
      "[[1 1 0 0 1 0 0 0 0]\n",
      " [1 3 0 0 0 2 0 1 1]\n",
      " [0 1 1 1 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"This is a content filtering model.\",\n",
    "    \"We are studying spam filtering. Spam filtering is a subfield of content filtering.\",\n",
    "    \"Filtering spams is interesting, and I am interested in it.\"\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(feature_names)\n",
    "print(X.toarray())\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(feature_names)\n",
    "print(X.toarray())\n",
    "# print(np.log(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(v):\n",
    "  if v >= 0:\n",
    "    return 1\n",
    "  return 0\n",
    "\n",
    "def neural_network_with_single_neuron(W, X, b):\n",
    "  Y = np.dot(np.array(W).T, np.array(X)) + b\n",
    "\n",
    "  return activation(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 0\n",
      "2 1\n",
      "3 0\n"
     ]
    }
   ],
   "source": [
    "W = [2, -4, 1]\n",
    "X = [[1, 0, 0], [0, 1, 1], [1, 0, 1], [1,1,1]]\n",
    "b = 0\n",
    "\n",
    "for i in range(len(X)):\n",
    "  print(i, neural_network_with_single_neuron(W, X[i], b))\n",
    "\n",
    "# print(neural_network_with_single_neuron(W, X, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "975",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
